---
title: "Parallel all papers PLS for corn data"
author: "Hongwei Peng"
date: "09/07/2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10 

###1~mp6 0.159

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###2~mp6 0.107

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###3~mp6 0.150

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###4~mp6 0.370

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#2 A strategy that iteratively retains informative variables for selecting optimal variable subset in multivariate calibration

##64-16 9 CV=5

###1~m5 RMSEC = 0.0149; RMSEP = 0.0201 

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 9                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    #RMSECV <- RMSEP(corn.pls)$val[1,1,NV]             #change RMSECV to RMSEC
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[DF$train,])
    RMSECV <- sqrt(sum((predict-DF[DF$train,]$y)^2)/(n))
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,100))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in) 3-fold but Loo better

###1~m5 0.040(5)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 5                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=3, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,100))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in) 3-fold

###2~m5 0.029(12)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 12                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=3, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```


#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in) 3-fold

###3~m5 0.119(6)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=3, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in) 3-fold but Loo better

###4~m5 0.196(6)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=3, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,100))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 12

###1~m5 0.3506

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 12                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 14

###2~m5 0.6912

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 14                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 8

###3~m5 0.4466

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 8                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 9

###4~m5 0.5010

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 9                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#5 Stability competitive adaptive reweighted sampling (SCARS) and its applications to multivariate calibration of NIR spectra

##40-40 Scale 10

###1~mp5 0.357

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(0,2,13) 7 5-fold

###2~m5 RMSECV=0.0729; RMSECP=0.0855

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,0,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,0,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,0,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 7                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(1,2,13) 7 5-fold

###2~m5 RMSECV=0.0577; RMSECP=0.0682

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 7                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(2,2,13) 7 5-fold

###2~m5 RMSECV=0.0370; RMSECP=0.0397

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,2,2,13)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,2,2,13)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,2,2,13)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 7                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(0,2,7) 8 5-fold

###4~m5 RMSECV=0.312; RMSECP=0.214

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,0,2,7)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,0,2,7)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,0,2,7)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 8                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(1,2,7) 8 5-fold

###4~m5 RMSECV=0.248; RMSECP=0.221

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,7)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,7)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,7)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 8                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 savitzkyGolay filler=(2,2,7) 8 5-fold

###4~m5 RMSECV=0.347; RMSECP=0.228

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,2,2,7)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,2,2,7)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,2,2,7)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 8                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=5, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    #plot(RMSEP(corn.pls), legendpos = "topright")     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],'\n')
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```


#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 savitzkyGolay filler=(1,2,21) (in)

###1~m5 0.045(06)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)  
library("MALDIquant")
library(prospectr)  
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```


#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 savitzkyGolay=(1,2,21) (in)

###2~m5 0.028(10) 

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 10                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 savitzkyGolay=(1,2,21) (in)

###3~m5 0.110(07)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 7                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 savitzkyGolay=(1,2,21) (in)

###4~m5 0.228(05)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 5                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)
```


#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77; 10

###1~m5 RMSECV=0.0124; RMSEP=0.0157

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=10, jackknife = TRUE, subset = train)
    #plot(RMSEP(gas1), legendpos = "topright")         #check point
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77; 13

###2~m5 RMSECV=0.0613; RMSEP=0.0673

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 13                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=10, jackknife = TRUE, subset = train)
    #plot(RMSEP(corn.pls), legendpos = "topright")         #check point
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,30))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77 13

###3~m5 RMSECV=0.1080; RMSEP=0.1353

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 13                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=10, jackknife = TRUE, subset = train)
    #plot(RMSEP(corn.pls), legendpos = "topright")         #check point
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  #par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77 10

###4~m5 RMSECV=0.2579; RMSEP=0.2356
  
```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="CV",K=10, jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

