---
title: "Parallel all papers PLS for corn data"
author: "Hongwei Peng"
date: "09/07/2019"
output: pdf_document
---

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10 

###1~mp6 0.159

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###2~mp6 0.107

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###3~mp6 0.150

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#1 A Partial Least Squares‐Based Consensus Regression Method for the Analysis of Near‐Infrared Complex Spectral Data of Plant Samples

##60-20 10

###4~mp6 0.370

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp6data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#2 A strategy that iteratively retains informative variables for selecting optimal variable subset in multivariate calibration

##64-16 10

###1~m5 RMSEC = 0.0149; RMSEP = 0.0201

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in)

###1~m5 0.040

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in)

###2~m5 0.029

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 12                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```


#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in)

###3~m5 0.119

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#3 Cross-validation for the selection of spectral variables using the successive projections algorithm

##60-20 SavitzkyGolay filler (in)

###4~m5 0.196

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 4

###1~m5 0.36

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 4                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 4

###2~m5 0.97

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 4                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 4

###3~m5 0.44

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 4                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#4 Reduced PCR/PLSR models by subspace projections

##40-40 Scale 4

###4~m5 0.49

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 4                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#5 Stability competitive adaptive reweighted sampling (SCARS) and its applications to multivariate calibration of NIR spectra

##40-40 Scale 10

###1~mp5 0.357

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls) 
    m5data <-  apply(rawdata$m5spec$data,2,scale)
    mp5data <-  apply(rawdata$mp5spec$data,2,scale)
    mp6data <-  apply(rawdata$mp6spec$data,2,scale) 
    propvals <- apply(rawdata$propvals$data,2,scale)
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(mp5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(40,50))                        #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 None 10

###2~m5 RMSECV=0.0363; RMSECP=0.04

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#6 Pretreating near infrared spectra with fractional order Savitzky–Golay differentiation (FOSGD)

##64-16 None 10

###4~m5 RMSECV=0.24; RMSECP=0.219

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    #m5data <- m5data[,c(-75,-77)]
    #propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(64,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  #cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 None (in)

###1~m5 0.045(06)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 6                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```


#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 None (in)

###2~m5 0.028(10) 

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 10                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  #PlotDataMean <- apply(PlotData,2,mean)
  #PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 None (in)

###3~m5 0.110(07)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 7                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  #PlotDataMean <- apply(PlotData,2,mean)
  #PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)

```

#7 A variable elimination method to improve the parsimony of MLR models using the successive projections algorithm

##60-20 None (in)

###4~m5 0.228(05)

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library("MALDIquant")
library(prospectr)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(prospectr)
    library(pls)
    m5data <-  t(apply(rawdata$m5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp5data <- t(apply(rawdata$mp5spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    mp6data <- t(apply(rawdata$mp6spec$data,1,function(x) {
      savitzkyGolay(x,1,2,21)                          #SavitzkyGolay filler
    }))
    propvals <- rawdata$propvals$data
    
    NV <- 5                                            #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(60,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)               #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS after scaled")
  boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS after scaled")
  #PlotDataMean <- apply(PlotData,2,mean)
  #PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],'\n')
})
stopCluster(cl)
```


#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77; 10

###1~m5 RMSECV=0.0124; RMSEP=0.0157

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,1])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```


#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77 10

###2~m5 RMSECV=0.0613; RMSEP=0.0673

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,2])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77 10

###3~m5 RMSECV=0.1080; RMSEP=0.1353

```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,3])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```

#8 Using consensus interval partial least square in near infrared spectra analysis

##52-26 Delete 75 , 77 10

###4~m5 RMSECV=0.2579; RMSEP=0.2356
  
```{r echo=FALSE,warning=FALSE,message=FALSE}
library(R.matlab)
library(pls) 
library(lars)
library(ggplot2)
library(parallel)                                      # 载入parallel包
clnum<-detectCores()-1                                 # 计算可用线程数，并设置并行使用线程数
cl <- makeCluster(getOption("cl.cores", clnum))        # 初始化并行
rawdata <- readMat("/Users/hongwei/Downloads/corn.mat")
clusterExport(cl, "rawdata")                           # 额外加载变量
system.time({
  corn_PLS=function(n){                                #n is the number of calibration
    library(pls)
    m5data <- rawdata$m5spec$data
    mp5data <- rawdata$mp5spec$data
    mp6data <- rawdata$mp6spec$data
    propvals <- rawdata$propvals$data
    m5data <- m5data[,c(-75,-77)]
    propvals <- propvals[,c(-75,-77)]
    
    NV <- 10                                           #number of variables 
    sample <- sample(1:80)                             #set random order; the begin of reset order
    DF <- data.frame(NIR = I(m5data),                  #input data
                     y=propvals[,4])
    class(DF$NIR) <- "matrix"                          # just to be certain, it was "AsIs"
    #str(DF)                                           #check point
    DF$train <- rep(FALSE, 80)
    DF$train[sample<=n] <- TRUE                        #chose calibration
    corn.pls <- plsr(y ~ NIR, data = DF, ncomp = NV, validation="LOO", jackknife = TRUE, subset = train)
    #summary(corn.pls,what="all")                      #check point
    RMSECV <- RMSEP(corn.pls)$val[1,1,NV]
    #print(RMSECV)                                     #check point
    predict <- predict(corn.pls, ncomp = NV, newdata = DF[!DF$train,])
    RMSEP <- sqrt(sum((predict-DF[!DF$train,]$y)^2)/(80-n))
    #print(RMSEP)                                      #check point
    #plot(R2(corn.pls))                                #check point
    return(cbind(RMSECV,RMSEP))                        #return 1x2matrix
  }
  #corn_PLS(n)
  n <- as.matrix(rep(52,50))                           #the number of calibration, rep(a:b,c): from a to b and repeat c. 
  #PlsResult <- apply(n,1,corn_PLS)                     #loop
  PlsResult <- parSapply(cl,n,corn_PLS)                #optimizated loop
  PlotData <- as.data.frame(cbind(n,t(PlsResult)))     #combind the results
  par(mfrow=c(1,2))
  #boxplot(V2~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSECV",main="PLS")
  #boxplot(V3~V1,data=PlotData,xlab="Number of Calibration", ylab="RMSEP",main="PLS")
  PlotDataMean <- apply(PlotData,2,mean)
  PlotDataSd <- apply(PlotData,2,sd)
  cat(PlotDataMean[2]-PlotDataSd[2],PlotDataMean[2],PlotDataMean[2]+PlotDataSd[2],"\n")
  cat(PlotDataMean[3]-PlotDataSd[3],PlotDataMean[3],PlotDataMean[3]+PlotDataSd[3],"\n")
})
stopCluster(cl)
```