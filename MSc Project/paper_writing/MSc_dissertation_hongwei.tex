\documentclass[a4paper,12pt,titlepage]{article} % [papersize,fontsize,add title page]{document type}

% This LaTeX file can be turned straight into a pdf by "PDFTeXify" in WinEdit, or
% by any LaTeX --> PDF command in another LaTeX editor
%
% Because figure files are PDF, LaTeX --> DVI does not work

% usepackage{.} reads in additional LaTeX packages
\usepackage[pdftex]{graphicx}       % to include graphs
\usepackage{natbib}                % A BibTeX style file for references.
\usepackage{amssymb,amsmath}        % for maths symbols and equation numbering
\usepackage{array,tabularx,calc}
\usepackage{multirow} % create the tables
\usepackage{lscape} %put table lscape
\usepackage{pdflscape} %put pages lscape

\newenvironment{conditions}[1][where:]
{%
	#1\tabularx{\textwidth-\widthof{#1}}[t]{
		>{$}l<{$} @{${}={}$} X@{}
	}%
}
{\endtabularx\\[\belowdisplayskip]}

% set up title page
\title{The NIR Corn Data Set}
\author{Hongwei PENG \vspace{2cm} \\
	Supervisor : Prof Tom Fearn \vspace{2cm} \\
	Department of Statistical Science \\
	University College London}
\date{\today} % \today gives today's date. ... or put in the date you want

% set page size and margins
\setlength{\textwidth}{17cm}
\setlength{\textheight}{26cm}
\setlength{\oddsidemargin}{-0.5cm}
\setlength{\evensidemargin}{-0.5cm}
\setlength{\topmargin}{-25mm}
\setlength{\parindent}{0cm}
\setlength{\parskip}{0.3cm}

\let\leq=\leqslant   % for nice-looking inequality signs
\let\geq=\geqslant

\numberwithin{equation}{section}  % equation numbers like (section#.equation#)

\linespread{1}     % 1: single-spacing, 2: double-spacing, 1.5: 1.5-spacing etc

\begin{document}   % start of document
	\maketitle         % create title etc
	\tableofcontents   % create table of contents
	\newpage           % start a new page
	
	The most readily available high-dimensional NIR spectroscopic data is called corn data. There are many algorithms for analysing corn data in many publications. These algorithms will often claim that their new algorithm has a better performs. So the purpose of this dissertation is to search for as many different papers as possible, and write a critical overall to find the most efficient measure that can evaluate whether the model performs well and quantify the improvements mentioned in the paper.
	
	\section{Introduction}             % start a new section called `Introduction'
	\label{sec:intro}                  % create label for this section
	
	\section{Literature reviews}
	\label{sec:liter}
	
	\section{Datasets}
	\label{sec:data}
	
	\section{Methodology}
	\label{sec:method}
	
	\subsection{Model Evaluation}
	\label{sec:eva}
	According to the corn data literature, there are several measures that can be used to evaluate the performance of the model.
	
	1, Root Mean Square Error for Calibration samples (RMSEC) is proposed by \citet{2yun2014strategy}.
	
	2, RMSECV is mentioned by many papers \citep{8ji2015using}. And there are two cross-validation methods. One is leave one out cross-validation (LOOCV), mentioned by \citet{6zheng2015pretreating}. The other is K-fold cross-validation, there are the 3-fold cross-validation \citep{3galvao2007cross}, 10-fold cross-validation \citep{8ji2015using} and so on. The calculation method of RMSECV is as follows:
	
	\begin{equation}
		RMSECV=\sqrt{\frac{1}{n}\sum_{i=1}^{n} (y_i-\hat y_i)^2} 
	\end{equation}
	\begin{conditions}
		n     &  the number of samples\\
		y_i     &   the experimental value of the i-th sample\\   
		\hat y_i &  the predicted value of the i-th sample by cross-validation which  includes removing the set of i-th sample from the calibration set, building a model with the remaining samples, and applying the model to i-th sample
	\end{conditions}
	
	3, The Root Mean Square Error of Prediction (RMSEP) is mentioned by \citet{1su2006partial}. This is a generally accepted method of evaluating models. This approach requires the determination of appropriate cross-validation sets and prediction sets before building PLS model. For example, 60 samples of corn data are used for a cross-validation and the remaining 20 samples are used as predictions \citep{1su2006partial}. Then the cross-validation data is used for modelling, determining the parameters for regression model, such as PLS. After that, the model is applied to the predictive data to calculate the Root Mean Square Error of Prediction (RMSEP). The RMSEP calculation formula is:
	
	\begin{equation}
RMSEP=\sqrt{\frac{1}{m}\sum_{i=1}^{m} (y_i-\hat y_i)^2}
	\end{equation}
	
	\begin{conditions}
		m     &  the number of prediction sets\\
		y_i     &  the experimental value of the i-th sample in the prediction set \\   
		\hat y_i &  the prediction value of model for the i-th sample
	\end{conditions}
	
	
	4, There are few papers mentioned that $R^2$ is used to measure the model \citep{tatavarti2005assessment}. But this method is also flawed. In some situations, not enough calculation accuracy of the computer will cause the value of $R^2$ to be equal to 1. For example, \citet{deng2016bootstrapping} has this problem and the $R^2$ in PLS model fitting  moisture is equl to 0.9959, but for the CARS, GA-PLS and BOSS model, $R^2$ are all equal to $1.0000 \pm 0.0000$. Hence we can see it hard to distinguish the different between models. So this will not be a good indicator of evaluation.
	
	\subsection{Pre-treatment}
	\label{sec:treat}
	The papers use different pre-treatments of the data, and the results of the model will be very different. For example, \citet{7galvao2008variable} and \citet{8ji2015using} both use M5 to predict the first constituent, and the results are very different. Through the different literatures, the common pretreatment of corn data has the following four types:
	
	1. Nothing to deal with \citep{1su2006partial}.
	
	2. Scale the data \citep{4ergon2006reduced}.
	
	3. SavitzkyGolay filter processing on the data \citep{3galvao2007cross}.
	
	4. Delete the outliers \citep{8ji2015using}.
	
	\subsection{Sample splitting}
	\label{splitting}
	The number of samples selected and the method of sample selection will also have an impact on the results of models. The methods of selecting samples are as follows:
	
	1. A completely random sample \citep{1su2006partial}.
	
	2. Choosing the samples by SPXY method \citep{3galvao2007cross}.
	
	3. Use the Kennard-Stone (K-S) algorithm \citep{zhao2015optimization}.
	
	4. Directly divide the raw data into the first half and the second half, the first half is cross-validation sets, and the second half is prediction set \citep{4ergon2006reduced}.
	
	The second and third methods will result in the prediction level data being very close to the data of the cross-validation set, which may increase the accuracy of the prediction and reduce the prediction difficulty, so these two methods are not used here. Because in the actual problem, the performance of the algorithm looks better when the two sample sets are too similar, which is not what we want. The last method relies on the sorting of the original data, so the next step is to take a random sampling method to simulate the sample. The selection of samples refers to \citet{5zheng2012stability} and \citet{6zheng2015pretreating}, so the sample size of 20 $\sim$ 70 will be selected as calibration to build the model, and the rest will selected as prediction.
	
	\subsection{Cross-validation}
	\label{cross-validation}
	The cross-validation is to divide the data into n groups. One of group is selected as the prediction set, and the remaining n-1 groups are used as the training set, and testing n times. Finally, the average of results of all tests was taken as the cross-validation result. If the selected n is the same as the size of sample, then this method is called leave one out method (LOO), otherwise it is called the k-fold cross-validation. Cross-validation not only improves the reliability of models, but also allows the model to avoid falling into local optimal solutions. Figure \ref{fig:cross-validation} shows the flow of the cross-validation.
	\begin{figure}[h]    % start of figure environment
		\centering           % put the graph(s) in the centre of the page (horizontally)
		\includegraphics[width=8.5cm, angle=0]{cross-validation.png}  % width changes size
	    \vspace*{-0.25cm}    % manual adjustment of vertical spacing
		\caption{The flow of the cross-validation}          % a meaningful caption
		\label{fig:cross-validation}               % label for the figure
	\end{figure}                        % end of figure environment
	
	The choice between LOO and k-fold cross-validation is determined according to the number of samples. When the sample size is small, the LOO is preferred. When the sample size is too large, the k-fold cross-test is preferred. There is an additional reminder here that the difference between LOO and the k-fold cross-validation is not just a difference in computing time. More, when the sample size is too large, LOO may cause over-fitting problems, and the k-fold cross-validation can not only save computational power, but also avoid the over-fitting problem in here. Chapter \ref{sec:Cross-Validation} will discuss the difference.
	
	\subsection{PLS algorithm}
	\label{PLS_al}
	The partial least squares regression (PLS) is a multi-regression technique proposed by \citet{wold1984collinearity}, and it is also the most common statistical method in the research of near-infrared spectroscopy. Partial least squares regression is similar to principal components analysis (PCA) and is also a factor analysis method. In the modelling  process, it is first necessary to decompose the matrix of spectrum and then extract a few principal components (these variables are called latent variables in PLS) to represent most of the information of original spectrum. Because the spectral data is high-dimensional, the number of independent variables is more than the number of samples, thus it cannot meet the basic assumption of least squares method. Therefore, it is necessary to extracting the data to some components, and then make the regression. Compared with PCA, PLS not only considers the dimensionality reduction of the independent variables, but also maximizes the covariance between the components and target variables. In this way, the covariance between the extracted components and the target vector will be the maximum. From this point, PLS is the improvement and further development of PCA, and the results in many applications also prove that PLS has better performance than PCA.
	
	The process of partial least squares regression is as follows:
	
	The PLS model needs to perform principal component decomposition on the spectral data matrix and the target vector when it is established.
	
	\begin{equation}
	X=TP^T+E 
	\end{equation}
	\begin{equation}
	Y=UQ^T+F
	\end{equation}
	Where T and P are the scoring matrix and the load matrix of the spectral matrix X, respectively. U and Q are the scoring matrix and the load matrix of the detection target vector Y, respectively. E and F are residual matrices of the spectral matrix X and the detection target vector Y, respectively, and T and U can perform linear regression as follows:
	......
	
	\subsection{Parallel computing}
	\label{parallel}
	
	\subsection{High performance computing system}
	\label{myriad}
	
	
	\section{Result and discussion}
	\label{sec:result}
	
	\subsection{Loop times}
	\label{sec:Loop times}
	\begin{figure}[h]    % start of figure environment
		\centering           % put the graph(s) in the centre of the page (horizontally)
		\includegraphics[width=15.5cm, angle=0]{no_loop_time500.pdf}  % width changes size
		\vspace*{-0.25cm}    % manual adjustment of vertical spacing
		\caption{RMSECV and RMSEP under different loop times}          % a meaningful caption
		\label{fig:looptimes}               % label for the figure
	\end{figure}                        % end of figure environment
	
	\subsection{Number of Samples}
	\label{sec:Number of Samples}
	
	\subsection{Number of Components}
	\label{sec:Number of Components}
	
	\subsection{Pre-treatment}
	\label{sec:Pre-treatment}
	
	\subsection{Cross-Validation}
	\label{sec:Cross-Validation}
	
	\subsection{Compare with papers}
	\label{sec:Compare with papers}
	
	\begin{landscape}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
	\begin{tabular}{llllllllllll}
		\hline
		\multirow{2}{*}{Paper} & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Data\\ set\end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}Calibration\\ set\end{tabular}} & \multirow{2}{*}{Pre-treatment}                                           & \multicolumn{2}{c}{Moisture}    & \multicolumn{2}{c}{Oil}         & \multicolumn{2}{c}{Protein}   & \multicolumn{2}{c}{Starch}    \\ \cline{5-12} 
		&                                                                     &                                                                            &                                                                          & RMSECV         & RMSEP          & RMSECV         & RMSEP          & RMSECV        & RMSEP         & RMSECV        & RMSEP         \\ \hline
		1                      & mp6                                                                 & 60                                                                         & None                                                                     &                & 0.1446034(10)  &                & 0.09225961(10) &               & 0.1400926(10) &               & 0.3436289(10) \\
		2                      & m5                                                                  & 64 5-fold                                                                  & None                                                                     & 0.01488358(10) & 0.02113168(10) &                &                &               &               &               &               \\
		3                      & m5                                                                  & 60                                                                         & SavitzkyGolay                                                            &                & 0.05628462(5)  &                & 0.03163213(12) &               & 0.1085697(6)  &               & 0.2371506(6)  \\
		4                      & m5                                                                  & 40                                                                         & Scale                                                                    &                & 0.05862355(12) &                & 0.3891674(14)  &               & 0.3554446(8)  &               & 0.3878001(9)  \\
		4                      & mp5                                                                 & 40                                                                         & Scale                                                                    &                & 0.4194983(12)  &                & 0.7190886(17)  &               & 0.3731878(8)  &               & 0.4980389(9)  \\
		5                      & mp5                                                                 & 40                                                                         & Scale                                                                    &                & 0.4023674(10)  &                &                &               &               &               &               \\
		6                      & m5                                                                  & 64 5-fold                                                                  & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(0,2,13)\end{tabular}  &                &                & 0.08331678(7)  & 0.07401861(7)  &               &               & 0.3322749(7)  & 0.2890035(7)  \\
		6                      & m5                                                                  & 64 5-fold                                                                  & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(1,2,13)\end{tabular}  &                &                & 0.06403154(7)  & 0.05660701(7)  &               &               & 0.2426438(7)  & 0.2287837(7)  \\
		6                      & m5                                                                  & 64 5-fold                                                                  & \begin{tabular}[c]{@{}l@{}}savitzkyGolay \\ filler=(2,2,13)\end{tabular} &                &                & 0.04751603(7)  & 0.03468245(7)  &               &               & 0.3216974(7)  & 0.3037632(7)  \\
		7                      & m5                                                                  & 60                                                                         & \begin{tabular}[c]{@{}l@{}}savitzkyGolay \\ filler=(1,2,21)\end{tabular} &                & 0.04043771(6)  &                & 0.04937681(10) &               & 0.1021954(7)  &               & 0.2630782(5)  \\
		8                      & m5                                                                  & 52                                                                         & Delete 75 , 77                                                           & 0.02177367(10) & 0.0197695(10)  & 0.06621319(10) & 0.05955603(10) & 0.1194857(10) & 0.1123115(10) & 0.2937006(10) & 0.2723313(10)
	\end{tabular}
\end{table}
\end{landscape}

	\begin{landscape}
\begin{table}[]
	\begin{tabular}{lllllllll}
		\hline
		Paper & \begin{tabular}[c]{@{}l@{}}Data\\ set\end{tabular} & \begin{tabular}[c]{@{}l@{}}Calibration\\ set\end{tabular} & Pre-treatment                                                            & \begin{tabular}[c]{@{}l@{}}RMSECV/\\ RMSEP\end{tabular} & Moisture       & Oil            & Protein       & Starch        \\ \hline
		1     & mp6                                                & 60                                                        & None                                                                     & RMSEP                                                   & 0.1446034(10)  & 0.09225961(10) & 0.1400926(10) & 0.3436289(10) \\
		2     & m5                                                 & 64 5-fold                                                 & None                                                                     & RMSECV                                                  & 0.01488358(10) &                &               &               \\
		2     & m5                                                 & 64 5-fold                                                 & None                                                                     & RMSEP                                                   & 0.02113168(10) &                &               &               \\
		3     & m5                                                 & 60                                                        & SavitzkyGolay                                                            & RMSEP                                                   & 0.05628462(5)  & 0.03163213(12) & 0.1085697(6)  & 0.2371506(6)  \\
		4     & m5                                                 & 40                                                        & Scale                                                                    & RMSEP                                                   & 0.05862355(12) & 0.3891674(14)  & 0.3554446(8)  & 0.3878001(9)  \\
		4     & mp5                                                & 40                                                        & Scale                                                                    & RMSEP                                                   & 0.4194983(12)  & 0.7190886(17)  & 0.3731878(8)  & 0.4980389(9)  \\
		5     & mp5                                                & 40                                                        & Scale                                                                    & RMSEP                                                   & 0.4023674(10)  &                &               &               \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(0,2,13)\end{tabular}  & RMSECV                                                  &                & 0.08331678(7)  &               & 0.3322749(7)  \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(0,2,13)\end{tabular}  & RMSEP                                                   &                & 0.07401861(7)  &               & 0.2890035(7)  \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(1,2,13)\end{tabular}  & RMSECV                                                  &                & 0.06403154(7)  &               & 0.2426438(7)  \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(1,2,13)\end{tabular}  & RMSEP                                                   &                & 0.05660701(7)  &               & 0.2287837(7)  \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay \\ filler=(2,2,13)\end{tabular} & RMSECV                                                  &                & 0.04751603(7)  &               & 0.3216974(7)  \\
		6     & m5                                                 & 64 5-fold                                                 & \begin{tabular}[c]{@{}l@{}}savitzkyGolay\\ filler=(2,2,13)\end{tabular}  & RMSEP                                                   &                & 0.03468245(7)  &               & 0.3037632(7)  \\
		7     & m5                                                 & 60                                                        & \begin{tabular}[c]{@{}l@{}}savitzkyGolay \\ filler=(1,2,21)\end{tabular} & RMSECV                                                  & 0.04043771(6)  & 0.04937681(10) & 0.1021954(7)  & 0.2630782(5)  \\
		8     & m5                                                 & 52                                                        & Delete 75 , 77                                                           & RMSECV                                                  & 0.02177367(10) & 0.06621319(10) & 0.1194857(10) & 0.2937006(10) \\
		8     & m5                                                 & 52                                                        & Delete 75 , 77                                                           & RMSEP                                                   & 0.0197695(10)  & 0.05955603(10) & 0.1123115(10) & 0.2723313(10)
	\end{tabular}
\end{table}
\end{landscape}

	\section{Conclusions}
	\label{sec:conclution}
	
	
	
	
	
	

	
	\addcontentsline{toc}{section}{References} % to add references to table of contents
	\bibliography{hongwei_pls_MSc}                     % read references from example.bib
	\bibliographystyle{chicago}            % file to determine the style of references
	
\end{document} 